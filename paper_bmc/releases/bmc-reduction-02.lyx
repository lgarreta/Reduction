#LyX 2.3 created this file. For more info see http://www.lyx.org/
\lyxformat 544
\begin_document
\begin_header
\save_transient_properties true
\origin unavailable
\textclass bmcart
\begin_preamble
%% BioMed_Central_Tex_Template_v1.06
\usepackage[T1]{fontenc}
%\usepackage{lmodern}
\usepackage{charter}


%\def\includegraphic{}
%\def\includegraphics{}

\startlocaldefs
\endlocaldefs
\end_preamble
\options twocolumn
\use_default_options true
\maintain_unincluded_children false
\language spanish
\language_package default
\inputencoding utf8
\fontencoding default
\font_roman "default" "default"
\font_sans "default" "default"
\font_typewriter "default" "default"
\font_math "auto" "auto"
\font_default_family default
\use_non_tex_fonts false
\font_sc false
\font_osf false
\font_sf_scale 100 100
\font_tt_scale 100 100
\use_microtype false
\use_dash_ligatures true
\graphics default
\default_output_format default
\output_sync 0
\bibtex_command default
\index_command default
\float_placement h
\paperfontsize default
\spacing single
\use_hyperref false
\papersize default
\use_geometry false
\use_package amsmath 1
\use_package amssymb 1
\use_package cancel 1
\use_package esint 1
\use_package mathdots 1
\use_package mathtools 1
\use_package mhchem 1
\use_package stackrel 1
\use_package stmaryrd 1
\use_package undertilde 1
\cite_engine basic
\cite_engine_type default
\biblio_style plain
\use_bibtopic false
\use_indices false
\paperorientation portrait
\suppress_date false
\justification true
\use_refstyle 1
\use_minted 0
\index Index
\shortcut idx
\color #008000
\end_index
\secnumdepth 3
\tocdepth 3
\paragraph_separation skip
\defskip smallskip
\is_math_indent 0
\math_numbering_side default
\quotes_style french
\dynamic_quotes 0
\papercolumns 1
\papersides 1
\paperpagestyle default
\tracking_changes false
\output_changes false
\html_math_output 0
\html_css_as_file 0
\html_be_strict false
\end_header

\begin_body

\begin_layout Standard
\begin_inset ERT
status collapsed

\begin_layout Plain Layout


\backslash
begin{frontmatter}
\end_layout

\begin_layout Plain Layout


\backslash
begin{fmbox}
\end_layout

\begin_layout Plain Layout


\backslash
dochead{Research}
\end_layout

\end_inset


\end_layout

\begin_layout Title
TRJCLUST: Un Algoritmo Rápido para Reducción de Trajectorias de Plegamiento
 de Proteínas
\end_layout

\begin_layout Standard
\begin_inset ERT
status collapsed

\begin_layout Plain Layout


\backslash
author[
\end_layout

\begin_layout Plain Layout

   addressref={aff1},                   % id's of addresses, e.g.
 {aff1,aff2}   
\end_layout

\begin_layout Plain Layout

   noteref={n1},                        % id's of article notes, if any
\end_layout

\begin_layout Plain Layout

   email={1uis.garreta@correounivalle.edu.co}   % email address
\end_layout

\begin_layout Plain Layout

]{
\backslash
inits{LG}
\backslash
fnm{Luis} 
\backslash
snm{Garreta}}
\end_layout

\begin_layout Plain Layout


\backslash
author[
\end_layout

\begin_layout Plain Layout

   addressref={aff2},
\end_layout

\begin_layout Plain Layout

   email={mmartinez@ebi.ac.uk}
\end_layout

\begin_layout Plain Layout

]{
\backslash
inits{MM}
\backslash
fnm{Mauricio} 
\backslash
snm{Martinez}}
\end_layout

\begin_layout Plain Layout


\backslash
author[
\end_layout

\begin_layout Plain Layout

   addressref={aff1},
\end_layout

\begin_layout Plain Layout

   corref={aff1},                       % id of corresponding address, if
 any
\end_layout

\begin_layout Plain Layout

   email={pedro.moreno@correounivalle.edu.co}
\end_layout

\begin_layout Plain Layout

]{
\backslash
inits{PM}
\backslash
fnm{Pedro A} 
\backslash
snm{Moreno}}
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout


\backslash
address[id=aff1]{%                           % unique id
\end_layout

\begin_layout Plain Layout

  
\backslash
orgname{Escuela de Ingeniería de Sistemas y Computación, Universidad del
 Valle}, % university, etc
\end_layout

\begin_layout Plain Layout

  %
\backslash
street{},                     %
\end_layout

\begin_layout Plain Layout

  %
\backslash
postcode{}                                % post or zip code
\end_layout

\begin_layout Plain Layout

  
\backslash
city{Santiago de Cali},                              % city
\end_layout

\begin_layout Plain Layout

  
\backslash
cny{Colombia}                                    % country
\end_layout

\begin_layout Plain Layout

}
\end_layout

\begin_layout Plain Layout


\backslash
address[id=aff2]{%
\end_layout

\begin_layout Plain Layout

  
\backslash
orgname{The European Bioinformatics Institute (EMBL-EBI)},
\end_layout

\begin_layout Plain Layout

  %
\backslash
street{D
\backslash
"{u}sternbrooker Weg 20},
\end_layout

\begin_layout Plain Layout

  %
\backslash
postcode{24105}
\end_layout

\begin_layout Plain Layout

  
\backslash
city{Hinxton, Cambridgeshire},
\end_layout

\begin_layout Plain Layout

  
\backslash
cny{UK}
\end_layout

\begin_layout Plain Layout

}
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset ERT
status collapsed

\begin_layout Plain Layout


\backslash
begin{artnotes}
\end_layout

\begin_layout Plain Layout


\backslash
note[id=n1]{Equal contributor} % note, connected to author
\end_layout

\begin_layout Plain Layout


\backslash
end{artnotes}
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset ERT
status collapsed

\begin_layout Plain Layout

%
\backslash
end{fmbox}% comment this for two column layout
\end_layout

\begin_layout Plain Layout


\backslash
begin{abstractbox}
\end_layout

\end_inset


\end_layout

\begin_layout Abstract
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
parttitle{Background}
\end_layout

\end_inset

 La simulación del proceso de plegamiento de proteínas es una de las principales
 herramientas para estudiar y comprender los mecanismos subyacentes en este
 proceso.
 Hoy en día estas simulaciones están llegando a unos tiempos de simulación
 que hasta hace algunos años eran imposibles de alcanzar y como consecuencia
 las trayectorias generadas son muy grandes.
 Analizar este tipo de trayectorias trae complicaciones debido a su tamaño
 y por lo tanto se necesita crear herramientas que logren reducirlas de
 tal manera que se logren preservar tanto los eventos principales como el
 orden temporal en el que ellos ocurren.
\end_layout

\begin_layout Abstract
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
parttitle{Results}
\end_layout

\end_inset

 Introducimos aquí un algoritmo de reducción para trayectorias grandes de
 plegamiento de proteínas que se caracteriza por dividar la trayectoria
 en segmentos y mediante una estrategia rápida de agrupamiento tomar los
 eventos más disimilares para luego seleccionar entre ellos a los 
\emph on
k
\emph default
 eventos más representativos.
 El algoritmo aprovecha el orden temporal implicito en la trayectoria para
 realizar en cada segmento comparaciones locales, entre eventos vecinos,
 y así evitar realizar una comparación de todos contra todos rque es muy
 costosa computacionalmente.
 
\end_layout

\begin_layout Abstract
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
parttitle{Conclusions}
\end_layout

\end_inset

 El esquema anterior permite que el algoritmo sea muy rápido y que los eventos
 seleccionados conserven su orden temporal dentro de la trayectoria.
 Además, el particionamiento en segmentos permite al algoritmo realizar
 la reducción por cada segmento de forma independiente y por lo tanto realizarse
 las reducciones de forma paralela lo que lo vuelve aún más rápido cuando
 se ejecuta en máquinas con procesadores de múltiples cores, como los PCs
 que se consiguen en el mercado hoy en día.
 Para mostrar la efectividad del algoritmo propuesto realizamos reducciones
 sobre tres conjuntos de trajectorias disponibles públicamente: las del
 supercomputador Anton, las del proyecto folding@home, y las del servidor
 de desplegamiento de Parasol.
\end_layout

\begin_layout Standard
\begin_inset ERT
status collapsed

\begin_layout Plain Layout


\backslash
begin{keyword}
\end_layout

\begin_layout Plain Layout


\backslash
kwd{Protein folding simulations}
\end_layout

\begin_layout Plain Layout


\backslash
kwd{Protein structure comparison}
\end_layout

\begin_layout Plain Layout


\backslash
kwd{Protein structure clustering}
\end_layout

\begin_layout Plain Layout


\backslash
end{keyword}
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout


\backslash
end{abstractbox}
\end_layout

\begin_layout Plain Layout


\backslash
end{fmbox}% uncomment this for two column layout 
\end_layout

\begin_layout Plain Layout


\backslash
end{frontmatter}
\end_layout

\end_inset


\end_layout

\begin_layout Section*
Background
\end_layout

\begin_layout Standard
\begin_inset Note Note
status collapsed

\begin_layout Plain Layout
Understanding the protein folding mechanism remains a grand challenge in
 structural biology.
 In the past several years, computational theories in molecular dynamics
 have been employed to shed light on the folding process.
 Coupled with high computing power and large scale storage, researchers
 now can computationally simulate the protein folding process in atomistic
 details at femtosecond temporal resolution.
 Such simulation often produces a large number of folding trajectories,
 each consisting of a series of 3D conformations of the protein under study.
 As a result, effectively managing and analyzing such trajectories is becoming
 increasingly important.
\end_layout

\end_inset


\end_layout

\begin_layout Standard
Las proteínas desempeñan funciones fundamentales en todos los seres vivos.
 Para que una proteína sea funcional, debe a partir de su cadena de aminoácidos
 plegarse hasta alcanzar una forma tridimensional (3D) única conocida como
 estado nativo.
 A este proceso se le llama el plegamiento de las proteínas y entender sus
 mecanismos y reglas ha sido uno de los objetivos más perseguidos dentro
 de la biología.
\end_layout

\begin_layout Standard

\color blue
Una herramienta de gran utilidad para estudiar este proceso es a través
 del análisis de las trayectorias generadas por las simulaciones de plegamiento,
 donde una trayectoria es una secuencia de conformaciones (representaciones
 3D) que describen 
\color red
las transiciones en función del tiempo que la proteína atraviesa en su proceso
 de plegamiento.
\end_layout

\begin_layout Standard
El método más usado en estas simulaciones es la dinámica molecular (DM)
 que por su costo computacional está limitada a proteínas pequeñas y a tiempos
 muy cortos.
 Sin embargo, nuevos avances tecnológicos evidencian un progreso notable
 en estas simulaciones.
 Recientemente en el 2016 se puso en operación la supercomputadora Anton-2
 
\begin_inset CommandInset citation
LatexCommand cite
key "Shaw2014"
literal "false"

\end_inset

, diez veces más rápida que su predecesora Anton-1, diseñada especialmente
 para el plegamiento de proteínas 
\begin_inset CommandInset citation
LatexCommand cite
key "Shaw2008"
literal "false"

\end_inset

 y de la cual ya se reportó en el 2011 las simulaciones completas de 12
 proteínas 
\begin_inset CommandInset citation
LatexCommand cite
key "Shaw2011"
literal "false"

\end_inset

, algunas en el o.
 En el 2014, usando unidades de procesamiento gráfico (GPUs) que son alternativa
s más económicas que Anton, se reportó las simulaciones de 17 proteínas
 en el orden de los microsegundos 
\color blue

\begin_inset CommandInset citation
LatexCommand cite
key "Nguyen2014"
literal "false"

\end_inset

.
 
\color inherit
Años antes, en el 2007 se usó computación distribuida en el proyecto folding@hom
e para simular el plegamiento de la proteína villin headpiece a partir de
 distintas conformaciones iniciales 
\color blue

\begin_inset CommandInset citation
LatexCommand cite
key "Larson2009"
literal "false"

\end_inset


\color inherit
.
 
\color blue
También se han usado otros métodos distintos a la DM, como el Probabilistic
 Roadmap Method que genera trayectorias de desplegamiento a partir de la
 estructura nativa de la proteína 
\color purple

\begin_inset CommandInset citation
LatexCommand cite
key "Amato2010"
literal "false"

\end_inset


\color blue
.
\end_layout

\begin_layout Standard

\color purple
Estos avances nos muestran que habrá un crecimiento notable en este tipo
 de simulaciones con tiempos en el orden de los microsegundos y milisegundos,
 y con trayectorias de varios millones de conformaciones.
 Además, muchas de estas trayectorias se están colocando a disposición pública,
 pero debido al gran número de conformaciones, su procesamiento y análisis
 en computadoras convencionales se vuelve muy costoso.
 De aquí que se necesiten algoritmos capaces de reducir estas trayectorias
 de una forma rápida, aprovechendo eficientemente los recursos de este tipo
 de máquinas, y buscando conservar la mayor información posible tanto a
 nivel de representación como a nivel de orden temporal.
\end_layout

\begin_layout Standard
Para realizar estas reducciones se han usado dos enfoques: la reducción
 de la dimensionalidad 
\begin_inset CommandInset citation
LatexCommand cite
key "Duan2013"
literal "false"

\end_inset

 y el agrupamiento 
\begin_inset CommandInset citation
LatexCommand cite
key "Peng2018"
literal "false"

\end_inset

.
 En el primer enfoque se transforma una conformación a un conjunto reducido
 de variables que la representan lo mejor posible.
 Para esto se han usado tanto técnicas lineales (e.g.
 análisis de componentes principales (PCA) y el escalamiento multi-dimensional
 
\begin_inset CommandInset citation
LatexCommand cite
key "RajanSchulten10"
literal "false"

\end_inset

) como no-lineales (e.g.
 Isomap 
\begin_inset CommandInset citation
LatexCommand cite
key "Das2006"
literal "false"

\end_inset

 y diffusion maps 
\begin_inset CommandInset citation
LatexCommand cite
key "Kim2015"
literal "false"

\end_inset

).
 Sin embargo, aunque se logra la reducción de las conformaciones, se pierde
 su representatividad como estructuras 3D (Figura 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:lost-info-dimensionality"
plural "false"
caps "false"
noprefix "false"

\end_inset

.A).
 Además, estas técnicas se vuelven costosas en tiempo cuando las trayectorias
 son muy grandes, ya que tienen que transformar todas sus conformaciones.
\end_layout

\begin_layout Standard

\color blue
En el segundo enfoque, agrupamiento, se asignan las conformaciones a grupos
 que comparten las mismas características (e.g.
 similaridad con la estructura nativa) y se toma de cada grupo ya sea un
 representante promedio ó sus características generales.
 Aquí se se han usado tanto agrupamientos particionales como jerárquicos
 (e.g.
 k-means 
\begin_inset CommandInset citation
LatexCommand cite
key "Doerr2017"
literal "false"

\end_inset

, linkage 
\begin_inset CommandInset citation
LatexCommand cite
key "Shao2007"
literal "false"

\end_inset

).
 Sin embargo, los grupos pierden su orden temporal ya que abarcan conformaciones
 que ocurren a tiempos muy distintos (
\color inherit
Figura 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:lost-info-dimensionality"
plural "false"
caps "false"
noprefix "false"

\end_inset

.
\color blue
Bu).
 Además, se tienen que comparar todos los pares de conformaciones, lo cual
 es muy costoso las trayectorias son muy grandes.
\end_layout

\begin_layout Standard
\begin_inset Float figure
placement !t
wide false
sideways false
status collapsed

\begin_layout Plain Layout
\align center
\begin_inset Box Frameless
position "t"
hor_pos "c"
has_inner_box 1
inner_pos "t"
use_parbox 0
use_makebox 0
width "100col%"
special "none"
height "1in"
height_special "totalheight"
thickness "0.4pt"
separation "3pt"
shadowsize "4pt"
framecolor "black"
backgroundcolor "none"
status open

\begin_layout Plain Layout

\series bold
A
\end_layout

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename img/2RN2-weakness-dimensionality.pdf
	lyxscale 30
	scale 21
	BoundingBox 0bp 15bp 1080bp 450bp
	clip

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout
\align center
\begin_inset Box Frameless
position "t"
hor_pos "c"
has_inner_box 1
inner_pos "t"
use_parbox 0
use_makebox 0
width "100col%"
special "none"
height "1in"
height_special "totalheight"
thickness "0.4pt"
separation "3pt"
shadowsize "4pt"
framecolor "black"
backgroundcolor "none"
status open

\begin_layout Plain Layout

\series bold
B
\end_layout

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename img/2RN2-weakness-clustering.pdf
	lyxscale 30
	scale 21
	BoundingBox 0bp 15bp 1080bp 450bp
	clip

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
csentence{Perdida de información en las reducciones.}
\end_layout

\end_inset

 (A) En la reducción de la dimensionalidad las conformaciones se transforman
 a un nuevo conjunto de valores y pierden su información estructural.
 (B) En el agrupamiento, las representantes R1 y R2 pierden su orden temporal
 ya que los grupos G1 y G2 contienen conformaciones C3 y C4 que se traslapan
 en el tiempo.
\begin_inset Newline newline
\end_inset


\begin_inset CommandInset label
LatexCommand label
name "fig:lost-info-dimensionality"

\end_inset


\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard

\color red
En este artículo presentamos un algoritmo para reducir trayectorias de plegamien
to que obtiene rápidamente conformaciones representativas, conservando tanto
 su estructura 3D como su orden temporal, y que es altamente paralelizable,
 aprovechando eficientemente las tecnologías multi-core presentes en las
 computadoras actuales.

\color purple
 El algoritmo presenta tres fases: particionamiento, caracterización, y
 extracción.
 El particionamiento divide la trayectoria en subtrayectorias para permitir
 reducirlas de forma independiente y facilitar su procesamiento en paralelo.

\color inherit
 La caracterización toma cada subtrayectoria y de una forma muy rápida seleccion
a las conformaciones que la caracterizan aprovechando su orden temporal.
 
\color purple
Y la extracción toma las conformaciones características de cada subtrayectoria
 y sobre toda su extensión extrae las más representativas.
\end_layout

\begin_layout Standard
El algoritmo está implementado en R, excepto la comparación entre conformaciones
 que usa una modificación de la métrica TM-Score 
\begin_inset CommandInset citation
LatexCommand cite
key "Zhan2004"
literal "false"

\end_inset

 y está implementada en Fortran como una librería externa.
\end_layout

\begin_layout Standard
\begin_inset Note Note
status open

\begin_layout Plain Layout
En este trabajo presentamos un algoritmo rápido para reducción de trayectorias
 de plegamiento de proteínas que toma como base la idea del algoritmo de
 Hobohm&Sander y que se basa en tres estrategias: primero una partición
 de la trayectoria en múltiples secciones; segundo, una reducción local
 muy rápida sobre cada una de ellas que aprovecha el tiempo de ocurrencia
 de las conformaciones; y tercero, una reducción global que busca encontrar
 las conformaciones más representativas de cada partición.
 Estas tres estrategias permiten que este algoritmo sea fácilmente paralelizable
, obtenga unos resultados previos de forma rápida, y de esos resultados
 seleccione los más importantes.
\end_layout

\begin_layout Plain Layout
Nuestro enfoque trabaja sobre las trayectorias de plegamiento ya realizadas
 y disponibles como un conjunto de snapshots a determinado 
\emph on
time step 
\emph default
y sobre estás realiza la selección de las más representativas por segmentos
 de tiempo que se ingresan como parámetros.
 El resultado es otra trayectoría con estructuras que representan de forma
 resumida la trayectoria original y que contiene los eventos o estructuras
 principales.
 El algoritmo se puede ajustar con diferentes parámetros para definir el
 tamaño de las particiones en número de conformaciones y número de representativ
as por cada partición, por ejemplo se puede definir que cada 1000 conformaciones
 se seleccionen 500 representativas, lo que reduce a la mitad el número
 de conformaciones, o cada 10000 conformaciones se selecciones 100, lo que
 la reduce a la trayectoria en 99%.
\end_layout

\end_inset


\end_layout

\begin_layout Standard
——————
\end_layout

\begin_layout Standard
\begin_inset Note Note
status collapsed

\begin_layout Plain Layout
La dinámica molecular (DM) es el método más usado para realizar estas simulacion
es las cuales 
\begin_inset Note Note
status collapsed

\begin_layout Plain Layout

\color blue
la cual requiere simulaciones largas (orden de los microsegundos o milisegundos)
 para poder observar eventos de plegamiento interesantes
\end_layout

\end_inset

 exigen grandes recursos computacionales que las limitan a tiempos muy cortos
 y a proteínas pequeñas.
 Sin embargo, desarrollos tecnológicos en esta ultima década han permitido
 avanzar en estas limitaciones y ya empiezan a publicarse varias trayectorias
 de gran tamaño para que sean analizadas por la comunidad científica.
\end_layout

\begin_layout Plain Layout

\color purple
Un gran avance lo hizo D.
 E.
 Shaw Research en el 2008 al crear la supercomputadora Anton 
\begin_inset CommandInset citation
LatexCommand cite
key "Shaw2008"
literal "false"

\end_inset

 diseñada especialmente para ejecutar DM.
 Luego, en el 2011 reportaron las simulaciones de 12 proteínas 
\begin_inset CommandInset citation
LatexCommand cite
key "Shaw2011"
literal "false"

\end_inset

 con trayectorias en la escala de los milisegundos y con más de 14 millones
 de conformaciones.

\color blue
 Años antes, en el 2007 el grupo de investigación de Pande usó computación
 distribuida en el proyecto folding@home 
\begin_inset CommandInset citation
LatexCommand cite
key "Larson2009"
literal "false"

\end_inset

 para simular el plegamiento de la proteína villin headpiece a partir de
 distintas condiciones iniciales y reportó alrededor de 1000 trayectorias,
 algunas de ellas en la escala de los microsegundos y con casi 2 millones
 de conformaciones 
\begin_inset CommandInset citation
LatexCommand cite
key "PandeEnsign07"
literal "false"

\end_inset

.

\color purple
 
\color inherit
Recientemente, en el 2016 se puso en operación Anton 2: la segunda generación
 de supercomputadoras Anton 
\begin_inset CommandInset citation
LatexCommand cite
key "Shaw2014"
literal "false"

\end_inset

 10 veces más rápidas que sus predecesoras 
\begin_inset CommandInset citation
LatexCommand cite
key "Shaw2008"
literal "false"

\end_inset

 y de las cuales se espera que empiecen a reportarse simulaciones en el
 orden de los milisegundos con trayectorias de varios millones de conformaciones.
 
\color blue
Sin embargo, como una alternativa más económica y accesible que Anton, se
 utilizan ahora las unidades de procesamiento gráfico (GPUs) para acelerar
 las simulaciones de DM y ya se reportan trayectorias del orden de los microsegu
ndos para diferentes proteínas 
\begin_inset CommandInset citation
LatexCommand cite
key "Nguyen2014"
literal "false"

\end_inset

.

\color inherit
 
\color purple
De forma paralela a todo lo anterior, se han utilizado métodos alternos
 a la DM como los algoritmos de planeación de movimiento 
\begin_inset CommandInset citation
LatexCommand cite
key "Al-Bluwi2012"
literal "false"

\end_inset

 que generan trayectorias de desplegamiento a partir de la estructura nativa
 de una proteína.
 Uno de estos métodos es el Probabilistic Roadmap Method 
\begin_inset CommandInset citation
LatexCommand cite
key "AmatoSong01,Amato2010"
literal "false"

\end_inset

 implementado en el servidor público de plegamiento de
\color inherit
 Parasol(
\begin_inset Flex URL
status collapsed

\begin_layout Plain Layout

http://parasol.tamu.edu/foldingserver/
\end_layout

\end_inset

).
\end_layout

\begin_layout Plain Layout
Vemos que se evidencia un crecimiento notable en las simulaciones de plegamiento
 de proteínas.
 Estas simulaciones van a generar nuevas trayectorias para más tipos de
 proteínas, tiempos de simulación más largos, del orden de los micro y milisegun
dos, y con millones de conformaciones.
 Esto vuelve costoso computacionalmente su procesamiento y análisis y es
 necesario simplificarlas eficientemente tratando de preservar lo más posible
 los eventos que mejor representen su plegamiento.
\end_layout

\end_inset


\end_layout

\begin_layout Standard
Hace algunos años Hobohm y Sander crearon una estrategia de agrupamiento
 muy rápido para seleccionar conjuntos representativos de secuencias de
 proteínas 
\begin_inset CommandInset citation
LatexCommand cite
key "Hobohm1992"
literal "false"

\end_inset

.
 
\color blue
Desde entonces la estrategia se ha utilizado en varios algoritmos de agrupamient
o rápido para distintos tipos de datos biológicos de gran tamaño 
\begin_inset CommandInset citation
LatexCommand cite
key "Liu2009,Edgar2010,Li2012b,Li2012"
literal "false"

\end_inset


\color inherit
.
 La estrategia realiza los agrupamientos sin necesidad de comparar todas
 las secuencias.
 Primero las ordena de forma decreciente por su longitud y toma la primera
 como representante del primer grupo.
 Luego toma la siguiente y la compara con las representantes de los grupos
 encontrados, si encuentra una que sea similar (de acuerdo a un umbral)
 la asigna a ese grupo o sino la coloca como representante de un nuevo grupo,
 y sigue así con las restantes.
\end_layout

\begin_layout Standard
como lo hacen otros algoritmos más comunes (e.g.
 k-means o single-linkage)
\end_layout

\begin_layout Standard
\begin_inset Note Note
status open

\begin_layout Plain Layout
Hobohm explanation through CD-HIT (Li2012)
\end_layout

\begin_layout Plain Layout
CD-HIT uses a greedy incremental algorithm.
 Basically, sequences are first ordered by decreasing length, and the longest
 one becomes the seed of the first cluster.
 Then, each remaining sequence is compared with existing seeds.
 If the similarity with any seed meets a pre-defined cutoff, it is grouped
 into that cluster; otherwise, it becomes the seed of a new cluster
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Note Note
status collapsed

\begin_layout Plain Layout
Para reducir estas trayectorias los métodos actuales buscan conjuntos de
 conformaciones representativas, que generalmente utilizan métodos de agrupamien
to donde se construye una matriz con las distancias entre cada una de las
 conformaciones, usualmente se usa la distancia conocida como RMSD o 
\emph on
Root Mean Square-Deviation
\emph default
.
 Estos agrupamientos se vuelven muy costosos en tiempo y recursos computacionale
s cuando se trata de muchas conformaciones y por esta razón los algoritmos
 buscan reducir estos costos, como por ejemplo, reducir el número de átomos
 que comparar en las conformaciones (solo carbonos alfa).
 
\end_layout

\begin_layout Plain Layout
Otra forma de reducir estas trayectorias es crear agrupamientos rápidos
 que no tengan que comparar todas las conformaciones, parecido a lo que
 realiza el algoritmo de Hobohm&Sander 
\begin_inset CommandInset citation
LatexCommand cite
key "Hobohm1992"
literal "true"

\end_inset

 para comparar secuencias de ADN.
 En este trabajo presentamos un algoritmo rápido para reducción de trayectorias
 de plegamiento de proteínas que toma como base la idea del algoritmo de
 Hobohm&Sander y que se basa en tres estrategias: primero una partición
 de la trayectoria en múltiples secciones; segundo, una reducción local
 muy rápida sobre cada una de ellas que aprovecha el tiempo de ocurrencia
 de las conformaciones; y tercero, una reducción global que busca encontrar
 las conformaciones más representativas de cada partición.
 Estas tres estrategias permiten que este algoritmo sea fácilmente paralelizable
, obtenga unos resultados previos de forma rápida, y de esos resultados
 seleccione los más importantes.
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Note Note
status collapsed

\begin_layout Plain Layout

\series bold
\size small
\lang american
Guide for background
\series default
 
\series bold
(Srivastava2016) :
\end_layout

\begin_layout Plain Layout

\series bold
\size small
\lang american
Importance:
\end_layout

\begin_layout Paragraph

\series medium
\size small
\lang american
Comparison of protein structures is an important for understanding structural,
 functional and evolutionary relationship among protein specially in case
 of novel proteins [1].
 In addition to this, it is being extensively used for identifying homologous
 residues [2, 3], finding recurrent folds [4], identifying structural motifs
 and functional sites, searching similar structure in structural database,
 predicting interaction among residues/proteins, and hierarchical classification
 of proteins [5, 6, 7, 8, 9, 10].
 Structural analysis of proteins is much more important than sequence analysis
 as protein structures are more conserved than sequences [1, 11].
 The comparison of protein can also be used for evaluation of sequence alignment
 methods [12, 13], prediction of unknown protein structures and evaluation
 of predicted 3D structure of a protein.
 
\end_layout

\begin_layout Paragraph

\series medium
\size small
\lang american
In the last two decades, research in the area of protein structure comparison
 has gained momentum but the problem of finding optimal alignment having
 significant role in biological context still continues [1].
 Number of methods for comparing two protein structures has been proposed
 in the literature.
 These methods are either based on various distance measures or scoring
 schemes.
 There is strong need to develop standard scoring function [14, 15] based
 on strong theoretical foundation as majority of existing techniques are
 heuristic in nature [1].
 These existing techniques are not only less accurate but have more computationa
l time and space complexity [16].
 Hence, there is a scope for improvement in the existing methods for better
 comparison of protein structures [1, 15, 17].
 
\end_layout

\begin_layout Paragraph

\series medium
\size small
\lang american
Algorithms of two protein 3D structures comparison approaches can be broadly
 classified into two categories, i.e., (1) is based on rigid body alignment
 by super positioning protein structures heuristically with scaling, rotation,
 transformation and then super-positioning [18] and (2) based on fragmentation
 of structures and assembling by non-sequential alignment [18, 19].
 The techniques of first category can perform better when the protein structures
 are small and each having equal number of residues in their sequences.
 The basic limitations of second category are selection of appropriate fragments
 size, computational time and space complexity for alignments.
 Various metrics for comparing and scoring identity between two protein
 structures are employed in both category of approaches, but the most commonly
 used are p values and root mean square deviation (RMSD).
 These metrics are rarely used for protein structure comparison with respect
 to single technique.
 Further, method such as Distance mAtrix aLIgnment (DALI) employ similarity
 score which is not a metric but it uses heuristic rule to search the neighborho
ods based on strong matches [20].
 Comparing of these techniques with respect to implementation and their
 practical utilities, these methods are difficult to use practically due
 to space and time complexity [21].
 
\end_layout

\begin_layout Paragraph

\series medium
\size small
\lang american
Recently, an attempt has been made for protein structure comparison using
 geodesic distance as dissimilarity score based on a particular Riemannian
 metric [22].
 In this technique 3D coordinates of backbone atoms have been used to derive
 parameterized curve in real numbers in three dimensional space i.e.
 R3, for representing the protein structures.
 The alignment of two protein structures is being defined as the alignment
 of the two curves derived from backbone atoms of two structures i.e., one
 from each protein.
 Each of these parameterized curve is represented by a special function
 called square root velocity function (SRVF).
 Further, shapes comparison has been done after removing all shape preserving
 transformations from these curves.
 It has been pointed out that this comparison can be improved further by
 using higher dimensional composite curves by concatenating the geometric
 (3D) coordinates with primary and secondary structures as auxiliary coordinates
 [23, 24] and side chain atoms.
 These side chain atoms play an important role in determination of protein
 structure and consequently protein functions.
 The orientations of side chains and molecular properties of residues have
 significant effect on protein conformational dynamics and hence the protein
 function [25].
 Therefore, the inclusion of the side chain atoms and molecular properties
 are likely to improve this protein structures comparative analysis and
 it may lead to a better alignment as compared to the alignment obtained
 from existing techniques.
 
\end_layout

\begin_layout Paragraph

\series medium
\size small
\lang american
Therefore, in this study an attempt has been made to develop a method/algorithm
 based on the elastic shape analysis [26, 27, 28, 29] considering both geometric
al and molecular properties of protein.
 In the proposed algorithm, side chain atoms along with molecular properties
 such as hydrophobicity, polarity, orientation (dihedral angles), mass of
 residues, functional group type (aliphatic, acyclic, hydroxyl or sulphur-contai
ning, aromatic) and number of side-chain atoms as auxiliary information
 have been included.
 The proposed technique requires significantly less time without compromising
 with the accuracy for comparing protein structures.
 The developed algorithm has been implemented using open source R software.
 The method has been elaborated stepwise in the âProposed algorithmâ
 section.
 The performance of the developed method was compared with the existing
 methods i.e., ESA [22, 23], combinatorial extension (CE) [30] and jFATCAT
 [31], Matt [32], multiple structural alignment algorithm (MUSTANG) [33]
 for which the details are provided in the âResults and discussionâ
 section.
 Our method was found to be more accurate for classification purpose and
 efficient in terms of computational time.
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Note Note
status collapsed

\begin_layout Plain Layout

\series bold
Hobohm algorithm flowchar 
\series default
(
\series bold
Kclust, Hauser2013)
\end_layout

\begin_layout Plain Layout
\begin_inset Graphics
	filename img/tmp-hobohm-algorithm-flowchar.png

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Note Note
status collapsed

\begin_layout Plain Layout

\series bold
Backgraound for fast clustering algorithms (Kclust, Hauser2013
\series default
): 
\end_layout

\begin_layout Paragraph

\series medium
\size small
CD-HIT [25-27] and UCLUST [28] are sequence clustering methods that, like
 kClust, do not rely on an external sequence search tool.
 All three methods aim at clustering large sequence databases much faster
 than what is possible using BLAST or FASTA.
 They start with zero clusters and pick one sequence after the other from
 the database.
 If the query is sufficiently similar to the representative sequence of
 a cluster, the query is added to that cluster.
 Otherwise it becomes the founding member and representative sequence for
 a new cluster.
 For the fast comparison of the query to the representative sequences of
 the clusters, these methods first prefilter the representative sequences
 using an alignment-free, k-mer-based sequence comparison.
 Sequences that pass the prefilter are aligned to the query using Smith-Waterman
 alignment.
 The clustering finishes when all sequences have been picked and assigned
 to a cluster.
\end_layout

\begin_layout Paragraph

\series medium
\size small
For prefiltering, CD-HIT and UCLUST simply count the number of identical
 k-mers between sequences.
 Because this number drops quickly as the similarity of the compared sequences
 decreases, CD-HIT uses shorter k-mers for achieving higher sensitivity:
 (e.
 g.
 5-mers for clustering thresholds down to 70% sequence identity, and 2-mers
 below 50%).
 The choice of k follows from the requirement for near-perfect sensitivity,
 between 95% and 99%.
 Reducing k comes at a considerable loss of speed, however, since decrementing
 k by one results in approximately 20 times more chance k-mers matches and
 a 20-fold longer run time.
 CD-HIT can therefore cluster large databases such as UniProt only to down
 to ∼ 50% sequence identity.
 UCLUST uses 5-mers at all clustering thresholds.
 This allows it to maintain a high speed even at low thresholds, at the
 cost of a loss of sensitivity.
 It ranks the representative sequences by the number of 5-mers they have
 in common with the query sequence and aligns them in this order until one
 of them is similar to the query sequence or until the highest-ranked eight
 clusters have been rejected.
 An apparent disadvantage of UCLUST is that, in order to increase sensitivity
 despite its word length of 5, it uses rather loose acceptance criteria.
 At clustering thresholds below 50%, this leads to a high fraction of corrupted
 clusters containing non-homologous sequences.
\end_layout

\begin_layout Paragraph

\series medium
\size small
Both CD-HIT and UCLUST use banded dynamic programming to speed up the Smith-Wate
rman search.
 In addition, UCLUST extends the alignment around identical 5-mer matches
 in a way similar to BLAST [11].
\end_layout

\end_inset


\end_layout

\begin_layout Standard
Text and results for this section, as per the individual journal's instructions
 for authors.
\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout

%
\backslash
cite{koon,oreg,khar,zvai,xjon,schn,pond,smith,marg,hunn,advi,koha,mouse}
\end_layout

\end_inset


\end_layout

\begin_layout Section*
Section title
\end_layout

\begin_layout Standard
Text for this section 
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
ldots
\end_layout

\end_inset


\end_layout

\begin_layout Subsection*
Sub-heading for section
\end_layout

\begin_layout Standard
Text for this sub-heading 
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
ldots
\end_layout

\end_inset


\end_layout

\begin_layout Subsubsection*
Sub-sub heading for section
\end_layout

\begin_layout Standard
Text for this sub-sub-heading 
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
ldots
\end_layout

\end_inset


\end_layout

\begin_layout Paragraph*
Sub-sub-sub heading for section
\end_layout

\begin_layout Standard
Text for this sub-sub-sub-heading 
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
ldots
\end_layout

\end_inset

 In this section we examine the growth rate of the mean of 
\begin_inset ERT
status open

\begin_layout Plain Layout

$Z_0$
\end_layout

\end_inset

, 
\begin_inset ERT
status open

\begin_layout Plain Layout

$Z_1$
\end_layout

\end_inset

 and 
\begin_inset ERT
status open

\begin_layout Plain Layout

$Z_2$
\end_layout

\end_inset

.
 In addition, we examine a common modeling assumption and note the importance
 of considering the tails of the extinction time 
\begin_inset ERT
status open

\begin_layout Plain Layout

$T_x$
\end_layout

\end_inset

 in studies of escape dynamics.
 We will first consider the expected resistant population at 
\begin_inset ERT
status open

\begin_layout Plain Layout

$vT_x$
\end_layout

\end_inset

 for some 
\begin_inset ERT
status open

\begin_layout Plain Layout

$v>0$
\end_layout

\end_inset

, (and temporarily assume 
\begin_inset ERT
status open

\begin_layout Plain Layout

$
\backslash
alpha=0$
\end_layout

\end_inset

)
\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
[
\end_layout

\begin_layout Plain Layout

 E 
\backslash
bigl[Z_1(vT_x) 
\backslash
bigr]= E
\end_layout

\begin_layout Plain Layout


\backslash
biggl[
\backslash
mu T_x
\backslash
int_0^{v
\backslash
wedge
\end_layout

\begin_layout Plain Layout

1}Z_0(uT_x)
\end_layout

\begin_layout Plain Layout


\backslash
exp 
\backslash
bigl(
\backslash
lambda_1T_x(v-u) 
\backslash
bigr)
\backslash
,du 
\backslash
biggr].
\end_layout

\begin_layout Plain Layout


\backslash
]
\end_layout

\end_inset


\end_layout

\begin_layout Standard
If we assume that sensitive cells follow a deterministic decay 
\begin_inset ERT
status open

\begin_layout Plain Layout

$Z_0(t)=xe^{
\backslash
lambda_0 t}$
\end_layout

\end_inset

 and approximate their extinction time as 
\begin_inset ERT
status open

\begin_layout Plain Layout

$T_x
\backslash
approx-
\backslash
frac{1}{
\backslash
lambda_0}
\backslash
log x$
\end_layout

\end_inset

, then we can heuristically estimate the expected value as
\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
begin{eqnarray}
\backslash
label{eqexpmuts}
\end_layout

\begin_layout Plain Layout

E
\backslash
bigl[Z_1(vT_x)
\backslash
bigr] &=& 
\backslash
frac{
\backslash
mu}{r}
\backslash
log x
\end_layout

\begin_layout Plain Layout


\backslash
int_0^{v
\backslash
wedge1}x^{1-u}x^{({
\backslash
lambda_1}/{r})(v-u)}
\backslash
,du
\end_layout

\begin_layout Plain Layout


\backslash
nonumber
\backslash

\backslash

\end_layout

\begin_layout Plain Layout

&=& 
\backslash
frac{
\backslash
mu}{r}x^{1-{
\backslash
lambda_1}/{
\backslash
lambda_0}v}
\backslash
log x
\backslash
int_0^{v
\backslash
wedge
\end_layout

\begin_layout Plain Layout

1}x^{-u(1+{
\backslash
lambda_1}/{r})}
\backslash
,du
\end_layout

\begin_layout Plain Layout


\backslash
nonumber
\backslash

\backslash

\end_layout

\begin_layout Plain Layout

&=& 
\backslash
frac{
\backslash
mu}{
\backslash
lambda_1-
\backslash
lambda_0}x^{1+{
\backslash
lambda_1}/{r}v} 
\backslash
biggl(1-
\backslash
exp 
\backslash
biggl[-(v
\backslash
wedge1) 
\backslash
biggl(1+
\end_layout

\begin_layout Plain Layout


\backslash
frac{
\backslash
lambda_1}{r}
\backslash
biggr)
\backslash
log x 
\backslash
biggr] 
\backslash
biggr).
\end_layout

\begin_layout Plain Layout


\backslash
end{eqnarray}
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\noindent
Thus we observe that this expected value is finite for all 
\begin_inset ERT
status open

\begin_layout Plain Layout

$v>0$
\end_layout

\end_inset

 (also see 
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
cite{koon,khar,zvai,xjon,marg}
\end_layout

\end_inset

).
\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout

%
\backslash
nocite{oreg,schn,pond,smith,marg,hunn,advi,koha,mouse}
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
begin{backmatter}
\end_layout

\end_inset


\end_layout

\begin_layout Section*
Competing interests
\end_layout

\begin_layout Standard
The authors declare that they have no competing interests.
\end_layout

\begin_layout Section*
Author's contributions
\end_layout

\begin_layout Standard
Text for this section 
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
ldots
\end_layout

\end_inset


\end_layout

\begin_layout Section*
Acknowledgements
\end_layout

\begin_layout Standard
Text for this section 
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
ldots
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset CommandInset bibtex
LatexCommand bibtex
btprint "btPrintCited"
bibfiles "reduccion-trayectorias"
options "bmc-mathphys"

\end_inset


\end_layout

\begin_layout Section*
Figures
\end_layout

\begin_layout Standard
\begin_inset Float figure
placement h
wide false
sideways false
status open

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
csentence{Sample figure title.} A short description of the figure content
 should go here.
\end_layout

\end_inset

 
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Standard
\noindent
\begin_inset Float figure
placement h
wide false
sideways false
status open

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
csentence{Sample figure title.} Figure legend text.
\end_layout

\end_inset

 
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Section*
Tables
\end_layout

\begin_layout Standard
\begin_inset Float table
placement !h
wide false
sideways false
status open

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
Sample table title.
 This is where the description of the table should go.
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Tabular
<lyxtabular version="3" rows="4" columns="4">
<features tabularvalignment="middle">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<row>
<cell alignment="center" valignment="top" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
B1
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
B2
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
B3
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
A1
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
0.1
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
0.2
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
0.3
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
A2
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
...
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
..
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
.
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
A3
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
...
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
.
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
.
\end_layout

\end_inset
</cell>
</row>
</lyxtabular>

\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Section*
Additional Files
\end_layout

\begin_layout Subsection*
Additional file 1 — Sample additional file title
\end_layout

\begin_layout Standard
Additional file descriptions text (including details of how to view the
 file, if it is in a non-standard format or the file extension).
  This might refer to a multi-page table or a figure.
\end_layout

\begin_layout Subsection*
Additional file 2 --- Sample additional file title
\end_layout

\begin_layout Standard
Additional file descriptions text.
\end_layout

\begin_layout Standard
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
end{backmatter}
\end_layout

\begin_layout Plain Layout


\backslash
end{document}
\end_layout

\end_inset


\end_layout

\end_body
\end_document
